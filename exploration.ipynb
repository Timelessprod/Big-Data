{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Big Data - Pyspark application\n",
    "\n",
    "Membres du groupe :\n",
    "\n",
    "| Noms             | UID   | Mail                      |\n",
    "|------------------|-------|---------------------------|\n",
    "| Adrien Merat     | 23745 | adrien.merat@epita.fr     |\n",
    "| Mehdi Oueslati   | 23550 | mehdi.oueslati@epita.fr   |\n",
    "| Emmanuel Mollard | 23082 | emmanuel.mollard@epita.fr |\n",
    "\n",
    "## Exploration des données\n",
    "\n",
    "### 1. Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import DenseMatrix\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import TimestampType, DoubleType, StringType, \\\n",
    "    StructField, StructType\n",
    "from pyspark.sql.functions import isnan, when, count, datediff, mean, lag, \\\n",
    "    col, month, year, weekofyear, date_format, dayofmonth, avg, stddev, desc, sum\n",
    "from pyspark.sql.window import Window\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Création de la session Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_spark_session(name: str) -> SparkSession:\n",
    "    \"\"\"\n",
    "    Create a spark session using the <name>\n",
    "    \"\"\"\n",
    "    return SparkSession.builder.appName(name).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(spark_session: SparkSession, path: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Create spark dataframe from the csv file at <path>\n",
    "    \"\"\"\n",
    "    dev_schema = StructType([\n",
    "        StructField(\"Date\", TimestampType()),\n",
    "        StructField(\"High\", DoubleType()),\n",
    "        StructField(\"Low\", DoubleType()),\n",
    "        StructField(\"Open\", DoubleType()),\n",
    "        StructField(\"Close\", DoubleType()),\n",
    "        StructField(\"Volume\", DoubleType()),\n",
    "        StructField(\"Adj Close\", DoubleType()),\n",
    "        StructField(\"company_name\", StringType()),\n",
    "    ])\n",
    "    return spark_session.read.csv(path, dev_schema, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Exploration des données\n",
    "\n",
    "#### 4.1. Comptage des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def count_nan(data_frame: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Count nan in the <df> DataFrame\n",
    "    \"\"\"\n",
    "    return data_frame.select([\n",
    "        count(when(isnan(c) | col(c).isNull(), c)).alias(c)\n",
    "        for c\n",
    "        in [\"High\", \"Low\", \"Open\", \"Close\", \"Volume\", \"Adj Close\"]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.2. Durée moyenne entre deux relevés\n",
    "\n",
    "On constate que les relevés sont fait tous les jours ouvrables, c'est-à-dire du lundi au vendredi. Il y a donc des trous causés par les weekends. Pour calculer la durée moyenne entre deux relevés, on utilise la fonction `datediff` qui calcule la différence entre deux dates. On fait cela pour chaque ligne en la comparant à la suivante, puis on fait une moyenne. On trouve une durée moyenne de 1,45 jours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def duration_between_rows(data_frame: DataFrame):\n",
    "    \"\"\"\n",
    "    Calculate the mean duration between each rows\n",
    "    \"\"\"\n",
    "    data_frame = data_frame.orderBy('Date')\n",
    "    data_frame = data_frame.withColumn('duration',\n",
    "                                       datediff(data_frame['Date'],\n",
    "                                                lag(data_frame['Date'], 1).over(\n",
    "                                                    Window.partitionBy(\"company_name\").orderBy('Date')))\n",
    "                                       )\n",
    "    return data_frame.select(mean('duration')).collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.3. Matrice de corrélation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def corr_matrix(data_frame: DataFrame) -> DenseMatrix:\n",
    "    \"\"\"\n",
    "    Return the correlation matrix of a dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    vector_col = \"corr_features\"\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=[\"High\", \"Low\", \"Open\", \"Close\", \"Volume\", \"Adj Close\"],\n",
    "        outputCol=vector_col\n",
    "    )\n",
    "    df_vector = assembler.transform(data_frame).select(vector_col)\n",
    "\n",
    "    matrix = Correlation.corr(df_vector, vector_col).collect()[0][0]\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On propose ci-dessous une fonction pour ajouter une visualisation graphique de la matrice de corrélation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_corr_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Plot the correlation matrix\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.matshow(matrix, cmap=plt.cm.GnBu, vmin=-1, vmax=1)\n",
    "    for (i, j), z in np.ndenumerate(matrix):\n",
    "        ax.text(j, i, '{:0.2f}'.format(z), ha='center', va='center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On écrit ci-dessous une fonction permettant de calculer la matrice de corrélation entre deux dataframes, afin de comparer deux compagnies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def correlate_two_dataframe(\n",
    "        df1:DataFrame,\n",
    "        df2:DataFrame,\n",
    "        col_in_df1:str,\n",
    "        col_in_df2:str = None) -> float:\n",
    "    \"\"\"\n",
    "    by default, col_in_df2 is equal to col_in_df1\n",
    "    \"\"\"\n",
    "    if col_in_df2 is None:\n",
    "        col_in_df2 = col_in_df1\n",
    "    if col_in_df1 == col_in_df2:\n",
    "        col_in_df2 = f'{col_in_df1}_2'\n",
    "        df2 = df2.withColumnRenamed(col_in_df1, col_in_df2)\n",
    "\n",
    "    df = df1.join(df2, 'Date', 'inner').select(col_in_df1, col_in_df2)\n",
    "    return df.stat.corr(col_in_df1, col_in_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.5. Moyennes sur une période"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def week_mean(data_frame: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Return average of each week for columns Open and Close\n",
    "    \"\"\"\n",
    "    return data_frame.withColumn(\"Year\", year(\"Date\")) \\\n",
    "        .withColumn(\"Week\", weekofyear(\"Date\")) \\\n",
    "        .groupBy(\"Year\", \"Week\") \\\n",
    "        .avg(\"Open\", \"Close\") \\\n",
    "        .orderBy([\"Year\", \"Week\"])\n",
    "\n",
    "\n",
    "def month_mean(data_frame: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Return average of each month for columns Open and Close\n",
    "    \"\"\"\n",
    "    return data_frame.withColumn(\"Year\", year(\"Date\")) \\\n",
    "        .withColumn(\"Month\", month(\"Date\")) \\\n",
    "        .groupBy(\"Year\", \"Month\") \\\n",
    "        .avg(\"Open\", \"Close\") \\\n",
    "        .orderBy([\"Year\", \"Month\"])\n",
    "\n",
    "\n",
    "def year_mean(data_frame: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Return average of each year for columns Open and Close\n",
    "    \"\"\"\n",
    "    return data_frame.withColumn(\"Year\", year(\"Date\")) \\\n",
    "        .groupBy(\"Year\") \\\n",
    "        .avg(\"Open\", \"Close\") \\\n",
    "        .orderBy(\"Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.6. Variation jour par jour & mois par mois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def change_day_to_day(df: DataFrame, col: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Add new column with comparaison between previous and next row value in column col\n",
    "    \"\"\"\n",
    "    df = df.orderBy('Date')\n",
    "    return df.withColumn(col + \"_change\",\n",
    "                         lag(df[col], 1).over(Window.partitionBy(\"company_name\").orderBy('Date')) - df[col]\n",
    "                         )\n",
    "\n",
    "def change_month_to_month(df: DataFrame, col_name: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Add new column with comparaison between previous and next month in column <col>\n",
    "    \"\"\"\n",
    "    return df.withColumn(\"Year\", year(\"Date\")) \\\n",
    "        .withColumn(\"Month\", month(\"Date\")) \\\n",
    "        .groupBy(\"Year\", \"Month\") \\\n",
    "        .avg(col_name) \\\n",
    "        .orderBy([\"Year\", \"Month\"]) \\\n",
    "        .withColumnRenamed(f'avg({col_name})', col_name) \\\n",
    "        .withColumn(col_name + \"_change\",\n",
    "                         col(col_name) - lag(col(col_name),\n",
    "                             1).over(Window.orderBy([\"Year\", \"Month\"]))\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.7. Graphique\n",
    "\n",
    "On propose un graphique en bougies pour diverses échelles temporelles (jour, mois, année)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def candle_sticks(data, Month: int, Year: int, saveoption: bool = None):\n",
    "    \"\"\"\n",
    "    data : pyspark dataframe\n",
    "    month : number related to the focus month\n",
    "    year : number related to the focus year\n",
    "    saveoption : save the figure into a file \"month_year.png\"\n",
    "    \"\"\"\n",
    "    data = data.withColumn('monthandday', date_format(data.Date, \"d MMM\"))\n",
    "    data = data.withColumn('day', dayofmonth(data.Date))\n",
    "    data = data.withColumn('month', month(data.Date))\n",
    "    data = data.withColumn('year', year(data.Date))\n",
    "\n",
    "    data = data.filter(data.month == Month).filter(data.year == Year)\n",
    "    pd_am = data.toPandas()\n",
    "    pd_am.index = pd_am.Date\n",
    "    pd_am = pd_am.drop(columns=\"Date\")\n",
    "    up = pd_am[pd_am.Close >= pd_am.Open]\n",
    "    down = pd_am[pd_am.Close < pd_am.Open]\n",
    "\n",
    "    heigh = 0.1\n",
    "    width = 0.5\n",
    "\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    plt.title(\"CandleStick Chart\")\n",
    "\n",
    "    plt.bar(up.monthandday, up.Close - up.Open, width, bottom=up.Open, color='green')\n",
    "    plt.bar(up.monthandday, up.High - up.Close, heigh, bottom=up.Close, color='green')\n",
    "    plt.bar(up.monthandday, up.Low - up.Open, heigh, bottom=up.Open, color='green')\n",
    "\n",
    "    plt.bar(down.monthandday, down.Close - down.Open, width, bottom=down.Open, color='red')\n",
    "    plt.bar(down.monthandday, down.High - down.Open, heigh, bottom=down.Open, color='red')\n",
    "    plt.bar(down.monthandday, down.Low - down.Close, heigh, bottom=down.Close, color='red')\n",
    "\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend([\"green\", \"red\"])\n",
    "    if saveoption:\n",
    "        sgd = str(Month) + '_' + str(Year)\n",
    "        plt.savefig(sgd)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.8. RSI (Relative Strength Index)\n",
    "\n",
    "L'indice de force relative (RSI) est un indicateur de momentum utilisé dans l'analyse technique qui mesure l'ampleur des récentes variations de prix pour évaluer les conditions de surachat ou de survente du prix d'une action ou d'un autre actif. Le RSI est affiché sous forme d'oscillateur (un graphique linéaire qui se déplace entre deux extrêmes) et peut avoir une lecture de 0 à 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def relative_strength_index(daf: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Add new column with relative strength index\n",
    "    \"\"\"\n",
    "    return daf.withColumn(\"rsi\", 100 - 100 / (1 + max(daf.Close - daf.Open, 0) / (daf.Open - daf.Close)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.9 Moving average\n",
    "\n",
    "Moyenne glissante de taille n sur la colonne spécifiée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_moving_average(stock_history: DataFrame, column: str, n: int = 5) -> DataFrame:\n",
    "    ordered_window = Window.partitionBy(\"company_name\").orderBy(\"Date\").rowsBetween(n, 0)\n",
    "    return stock_history.withColumn(\"daily_average\", avg(stock_history[column]).over(ordered_window))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.10. Volatilité\n",
    "\n",
    "Écart entre les extrêmes et la moyenne sur une période donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_volatility(df: DataFrame, start_date: TimestampType() = None, end_date: TimestampType() = None, n: int = 5):\n",
    "    if start_date is not None and end_date is not None:\n",
    "        selected_df = df.filter(col(\"Date\") <= start_date).filter(col(\"Date\") <= end_date)\n",
    "    else:\n",
    "        selected_df = df\n",
    "    selected_w_average = compute_moving_average(selected_df, \"Close\", n)\n",
    "    return selected_w_average.select(stddev(\"daily_average\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.11. Momentum\n",
    "\n",
    "Vitesse de variation du prix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_momentum(stock_history: DataFrame, n: int = 5) -> DataFrame:\n",
    "    return compute_moving_average(stock_history, \"Close\", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.12. Upside downside ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def upside_downside_ratio(stocks) -> DataFrame:\n",
    "    curated_stocks = []\n",
    "    for i, stock in enumerate(stocks):\n",
    "        stock_w_advancements = stock.withColumn(f\"advancement_{i}\", (stock[\"Close\"] - stock[\"Open\"]) * stock[\"Volume\"])\n",
    "        advancements_only = stock_w_advancements.select(\"Date\", f\"advancement_{i}\")\n",
    "        curated_stocks.append(advancements_only)\n",
    "\n",
    "    all_joined = curated_stocks[0]\n",
    "    for df_next in curated_stocks[1:]:\n",
    "        all_joined = all_joined.join(df_next, on='Date', how='inner')\n",
    "\n",
    "    def gen_pos(frame: DataFrame, pred: callable):\n",
    "        res = frame[\"advancement_0\"] * (frame[\"advancement_0\"] > 0).cast(\"double\")\n",
    "        for index in range(len(stocks) - 1):\n",
    "            res += frame[f\"advancement_{index + 1}\"] * (pred(frame[f\"advancement_{index + 1}\"])).cast(\"double\")\n",
    "        return res\n",
    "\n",
    "    out = all_joined.withColumn(\"total_upside\", gen_pos(all_joined, lambda x: x > 0))\n",
    "    out = out.withColumn(\"total_downside\", gen_pos(out, lambda x: x < 0))\n",
    "    out = out.withColumn(\"upside_downside_ratio\", out[\"total_upside\"] / out[\"total_downside\"])\n",
    "    out = out.select(\"Date\", \"upside_downside_ratio\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.14. Moyenne sur une période"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_average_over_period(frame: DataFrame, col_name: str, start_date: TimestampType(),\n",
    "                                end_date: TimestampType()):\n",
    "    return frame.filter(col(\"Date\") >= start_date).filter(col(\"Date\") <= end_date).agg(avg(col(col_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.15 Daily return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_daily_return(frame: DataFrame) -> DataFrame:\n",
    "    return frame.withColumn(\"daily_return\", (frame[\"Close\"] - frame[\"Open\"]) / frame[\"Open\"] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.17. Return rate sur une période donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_return_rate_over_period(frame: DataFrame, start_date: TimestampType(), end_date: TimestampType()):\n",
    "    curated_frame = frame.filter(col(\"Date\") >= start_date).filter(col(\"Date\") <= end_date)\n",
    "    open_val = curated_frame.filter(col(\"Date\") == start_date).head(1)[0].__getitem__(\"Open\")\n",
    "    close_val = curated_frame.filter(col(\"Date\") == end_date).head(1)[0].__getitem__(\"Close\")\n",
    "    return (close_val - open_val) / open_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.18. Plus haut gain dans une journée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def highest_daily_return(stocks) -> DataFrame:\n",
    "    stocks_w_daily_return = list(map(lambda x: compute_daily_return(x), stocks))\n",
    "    all_joined = stocks_w_daily_return[0]\n",
    "    for df_next in stocks_w_daily_return[1:]:\n",
    "        all_joined = all_joined.union(df_next)\n",
    "    return all_joined.sort(desc('daily_return')).dropDuplicates(['date']).select(\"Date\", \"company_name\", \"daily_return\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.19. Plus haut retour sur une période donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def highest_period_return(stocks, start_date: TimestampType(), end_date: TimestampType()):\n",
    "    highest_val = compute_return_rate_over_period(stocks[0], start_date, end_date)\n",
    "    name = stocks[0].head(1)[0].__getitem__(\"company_name\")\n",
    "    for stock in stocks[1:]:\n",
    "        return_rate = compute_return_rate_over_period(stock, start_date, end_date)\n",
    "        if return_rate > highest_val:\n",
    "            highest_val = return_rate\n",
    "            name = stock.head(1)[0].__getitem__(\"company_name\")\n",
    "    return name, highest_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.20. Index du momentum sur une journée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_intraday_momentum_index(stock: DataFrame, n: int = 14):\n",
    "    ordered_window = Window.partitionBy(\"company_name\").orderBy(\"Date\").rowsBetween(-1 * n, 0)\n",
    "    stock_w_daily_gains = stock.withColumn(\"daily_gain\", stock[\"Close\"] - stock[\"Open\"])\n",
    "    stock_w_daily_gl = stock_w_daily_gains.withColumn(\"daily_loss\",\n",
    "                                                      stock_w_daily_gains[\"Open\"] - stock_w_daily_gains[\"Close\"])\n",
    "    stock_w_daily_gbool = stock_w_daily_gl.withColumn(\"gain_bool\",\n",
    "                                                      (stock_w_daily_gl[\"Close\"] > stock_w_daily_gl[\"Open\"])\n",
    "                                                      .cast(\"Double\"))\n",
    "    stock_w_daily_glbool = stock_w_daily_gbool.withColumn(\"loss_bool\",\n",
    "                                                          (stock_w_daily_gbool[\"Open\"] > stock_w_daily_gbool[\"Close\"])\n",
    "                                                          .cast(\"Double\"))\n",
    "    stock_w_daily_netg = stock_w_daily_glbool.withColumn(\"net_gain\", stock_w_daily_glbool[\"daily_gain\"] *\n",
    "                                                         stock_w_daily_glbool[\"gain_bool\"])\n",
    "    stock_w_daily_netgl = stock_w_daily_netg.withColumn(\"net_loss\", stock_w_daily_netg[\"daily_loss\"] *\n",
    "                                                         stock_w_daily_glbool[\"loss_bool\"])\n",
    "    stock_w_momentum_gains = stock_w_daily_netgl.withColumn(\"mgains\", sum(stock_w_daily_netgl[\"net_gain\"])\n",
    "                                                            .over(ordered_window))\n",
    "    stock_w_mgl = stock_w_momentum_gains.withColumn(\"mlosses\", sum(stock_w_momentum_gains[\"net_loss\"])\n",
    "                                                    .over(ordered_window))\n",
    "    stock_w_imi = stock_w_mgl.withColumn(\"imi\", stock_w_mgl[\"mgains\"] /\n",
    "                                         (stock_w_mgl[\"mgains\"] + stock_w_mgl[\"mlosses\"]) * 100)\n",
    "    return stock_w_imi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### 4.21. Index du flux de monnaie sur une période donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_money_flow_index(stock: DataFrame, n: int = 14):\n",
    "    ordered_window = Window.partitionBy(\"company_name\").orderBy(\"Date\").rowsBetween(-1 * n, 0)\n",
    "    one_window = Window.partitionBy(\"company_name\").orderBy(\"Date\")\n",
    "    stock_w_typical = stock.withColumn(\"typical_price\", stock[\"High\"] + stock[\"Low\"] + stock[\"Close\"])\n",
    "    stock_w_raw = stock_w_typical.withColumn(\"raw_money_flow\",\n",
    "                                             stock_w_typical[\"typical_price\"] * stock_w_typical[\"Volume\"])\n",
    "    stock_w_is_pos = stock_w_raw.withColumn(\"is_pos_flow\",\n",
    "                                            (lag(stock_w_raw[\"typical_price\"]).over(one_window)\n",
    "                                             < stock_w_raw[\"typical_price\"])\n",
    "                                            .cast(\"Double\"))\n",
    "    stock_w_ispl = stock_w_is_pos.withColumn(\"is_neg_flow\",\n",
    "                                             (lag(stock_w_is_pos[\"typical_price\"]).over(one_window)\n",
    "                                              > stock_w_is_pos[\"typical_price\"])\n",
    "                                             .cast(\"Double\"))\n",
    "    stock_w_period_pos = stock_w_ispl.withColumn(\"pos_period_flow\",\n",
    "                                                 sum(stock_w_ispl[\"is_pos_flow\"] * stock_w_ispl[\"raw_money_flow\"])\n",
    "                                                 .over(ordered_window))\n",
    "    stock_w_period_pn = stock_w_period_pos.withColumn(\"neg_period_flow\",\n",
    "                                                      sum(stock_w_period_pos[\"is_neg_flow\"] * stock_w_period_pos[\n",
    "                                                          \"raw_money_flow\"])\n",
    "                                                      .over(ordered_window))\n",
    "    stock_w_ratio = stock_w_period_pn.withColumn(\"money_flow_ratio\",\n",
    "                                                 stock_w_period_pn[\"pos_period_flow\"] / stock_w_period_pn[\n",
    "                                                     \"neg_period_flow\"])\n",
    "    return stock_w_ratio.withColumn(\"money_flow_index\", 100 / (1 + stock_w_ratio[\"money_flow_ratio\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Description de la dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def describe_data_frame(data_frame: DataFrame):\n",
    "    \"\"\"\n",
    "    Describe the dataframe\n",
    "    - print the first and last 40 lines\n",
    "    - print the number of observations\n",
    "    - print the period between the data points\n",
    "    - print the min, max, mean and standard deviation\n",
    "    - print the number of missing values for each dataframe and column\n",
    "    - print correlation matrix\n",
    "    \"\"\"\n",
    "    print(\"Dataframe schema:\")\n",
    "    data_frame.printSchema()\n",
    "\n",
    "    print(\"First 40 lines:\")\n",
    "    data_frame.show(40)\n",
    "\n",
    "    print(f\"Number of observations: {data_frame.count()}\\n\")\n",
    "\n",
    "    print(\"Period between data points:\")\n",
    "    print(duration_between_rows(data_frame))\n",
    "\n",
    "    # Descriptive statistics for each dataframe and each column (min, max,\n",
    "    # standard deviation)\n",
    "    data_frame.describe().show()\n",
    "\n",
    "    print(\"Number of missing values for each dataframe and column:\")\n",
    "    count_nan(data_frame).show()\n",
    "\n",
    "    print(\"Correlation between 'High' and 'Low':\")\n",
    "    pearson_corr = data_frame.stat.corr('High', 'Low')\n",
    "    print(pearson_corr)\n",
    "    print(\"Correlation matrix:\")\n",
    "    corr = corr_matrix(data_frame)\n",
    "    print(corr, '\\n')\n",
    "\n",
    "    print(\"RSI\")\n",
    "    # relative_strength_index(data_frame).select(\"rsi\").describe()\n",
    "\n",
    "    print(\"Moving Average\")\n",
    "    avgdf = compute_moving_average(data_frame, \"Close\")\n",
    "    avgdf.show()\n",
    "\n",
    "    print(\"volatility\")\n",
    "    format_date = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start = datetime.datetime.strptime(\"2019-04-18 00:00:00\", format_date)\n",
    "    end = datetime.datetime.strptime(\"2019-05-16 00:00:00\", format_date)\n",
    "    vol = compute_volatility(data_frame, start, end)\n",
    "    vol.show()\n",
    "    print(f\"average opening from {start} to {end}\")\n",
    "    compute_average_over_period(data_frame, \"Open\", start, end).show()\n",
    "    print(f\"average closing from {start} to {end}\")\n",
    "    compute_average_over_period(data_frame, \"Close\", start, end).show()\n",
    "    print(\"daily return rate\")\n",
    "    compute_daily_return(data_frame).show()\n",
    "    print(f\"return rate from {start} to {end}\")\n",
    "    print(compute_return_rate_over_period(data_frame, start, end))\n",
    "    print(\"IMI score\")\n",
    "    compute_intraday_momentum_index(data_frame).show()\n",
    "    print(\"Money Flow Index\")\n",
    "    compute_money_flow_index(data_frame).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. Fonction `main()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "La fonction ci-dessous appelle les fonctions précédentes pour réaliser les graphiques et calculer les valeurs demandées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    spark = create_spark_session(\"Spark_Application_Name\")\n",
    "    all_datasets = []\n",
    "    for f in ['AMAZON.csv', 'APPLE.csv', 'FACEBOOK.csv', 'GOOGLE.csv',\n",
    "              'MICROSOFT.csv', 'TESLA.csv', 'ZOOM.csv']:\n",
    "        print(f\"\\n{f}:\")\n",
    "        df = load_data(spark, 'stocks_data/' + f)\n",
    "        all_datasets.append(df)\n",
    "        describe_data_frame(df)\n",
    "    print(\"upside_downside_ratio\")\n",
    "    upside_downside_ratio(all_datasets).show()\n",
    "    print(\"highest daily return\")\n",
    "    highest_daily_return(all_datasets).show()\n",
    "    date_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start = datetime.datetime.strptime(\"2019-04-18 00:00:00\", date_format)\n",
    "    end = datetime.datetime.strptime(\"2019-05-16 00:00:00\", date_format)\n",
    "    print(f\"highest return from {start} to {end}\")\n",
    "    print(highest_period_return(all_datasets, start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68d2b8b5e2aa1df71402d501bab0acb61cb02fdad3cc0365ec07b9781d66f1cc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
